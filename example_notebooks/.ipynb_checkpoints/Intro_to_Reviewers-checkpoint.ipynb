{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2aedd2d-b1d5-4d2d-8e95-61ff06292438",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Intro to Reviewers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b00f28-154a-45a5-b4fb-1d3afbb0c3ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## The problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7b77e1-2824-48d1-ac2e-4a932b4ce85e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Why and how we review data\n",
    "\n",
    "Part of any study is ensuring data across multiple sources are consistent, and coming to conclusions about the data given additional context. Studies are often novel, and frequently there are steps along the way that do not have existing automation techniques. Even of such techniques exist, one may still be skeptical in case the data breaks any assumptions. \n",
    "\n",
    "Typically, those reviewing all this data opens a bunch of windows to view data from different places (a clinical information spreadsheet from a collaborator, a few outputs from a Terra workflow, and/or previous notes from another reviewer, etc.). Next they look at all the data and keep notes in yet a separate document, such as a spreadsheet or digital/physical notes. Then, they go row by row, sample by sample, until they finish.\n",
    "\n",
    "### Why we need something better\n",
    "\n",
    "While straightforward to do in theory, this review method is very brittle, error prone, and very time consuming. \n",
    "\n",
    "Reviewing can take a very long time, such as reviewing large datasets on the order of hundreds to thousands of data points, or if the review needs to be repeated multiple times if something upstream changes. \n",
    "\n",
    "Some review processes are iterative, or new information is gained from some other source to inform the review process, or we need to pass off the review process to someone else. We should be able to easily incorporate old data with new data, and share that history and information with others.\n",
    "\n",
    "Some reviews require calculations, or exploring the the data in ways that a static plot cannot provide. Some Terra workflows do produce some interactive html files, but this is rare. Sometimes, a reviewer realizes in the process of reviewing a different kind of plot could be very informative for the review process. It should be easy to generate such a plot on the fly without having to modify or create a new Terra workflow, or opening a new notebook to calculate manually.\n",
    "\n",
    "Lastly, humans are humans, and we make mistakes. It can be very tedious to maintain and update a large spreadsheet with hundreds of rows and multiple columns to annotate. Annotations are difficult to enforce in this setting, and changes are difficult to track. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f282c4d7-2fa6-4da3-8115-f860ea207980",
   "metadata": {},
   "source": [
    "## The Solution: Jupyter notebook and Plotly-Dash!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e47d0a-46f8-450f-bc5c-59b189516003",
   "metadata": {},
   "source": [
    "Most ACBs use jupyter notebooks for their analysis. So why not keep the review process in jupyter notebooks too? Additionally, there already exist great tools for making interactive figures and dashboards. We can use these packages to help automatically consildate information and create figures that will make it easier to review, enforce annotation standards, and track changes over time.\n",
    "\n",
    "The `JupyterReviewer` package makes it simple to create dashboards for reviewing data. Developers and users can easily customize their dashboards to incorpate any data they like, and automatically provides a reviewer an easy way to annotate their data, track changes, and share their annotations with others.\n",
    "\n",
    "Below is an overview of what you need to know about this package to get started.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670b8f2a-af59-4f15-8551-fa038ea8849e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d4fe42-17fe-4ea6-aaa7-85b7c0718788",
   "metadata": {},
   "source": [
    "1. Download the repository: `git clone git@github.com:getzlab/JupyterReviewer.git` \n",
    "1. `cd JupyterReviewer`\n",
    "1. Create an environment: `conda create --name <my-env> --file requirements.txt`\n",
    "1. Install package: `pip install -e .`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01850b1f-4f86-4da2-b23a-bd48c33c6844",
   "metadata": {},
   "source": [
    "# ReviewData object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c126d214-47e7-412f-a467-755af57ec654",
   "metadata": {},
   "source": [
    "The `ReviewData` object is simply 3 tables that tracks what data you are looking at for your review, the annotations you made, and the history of your annotations. It is meant to mirror how one may go about annotations by going row by row in a spreadsheet, and filling in/editing the corresponding columns. The object is saved to a pickle file object (provided by the user), which can be shared or exported to a tsv file.\n",
    "\n",
    "The only rule is each row corresponds to specific data item you want to annotated. It is independent of the other rows in the table. it can be a sample, a participant, a pair, a mutation, etc.\n",
    "\n",
    "Recommendations:\n",
    "- Do as much automation for annotations as possible first. You can use this tool to manually check and update these annotations\n",
    "- Preprocess your files so when each sample's data is rendered, it will take less time to switch between samples.\n",
    "\n",
    "How do you add and save annotations? The `ReviewDataApp` handles this. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35152182-c4be-47ac-a304-cde057b03720",
   "metadata": {},
   "source": [
    "# ReviewDataApp object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c47b85-b26c-48cd-bb34-2bb7d878f57c",
   "metadata": {},
   "source": [
    "The `ReviewDataApp` is simply a wrapper to make it easy to review data and add annotations, with the additional benefit of adding custom tables and graphs to help analyze and see all the relevant data all at once. It is built around plotly dash, and package that makes it easy to create interactive figures and custom dashboards. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6da5e46-e97c-47c1-b029-bb652877edb8",
   "metadata": {},
   "source": [
    "# Get started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f26fa18-fc1c-4505-a283-f098c3382aa6",
   "metadata": {},
   "source": [
    "1. Get a pandas dataframe with the data you want to review. Each item to review must have a unique index name (ie a sample_id, participant_id, etc.)\n",
    "1. Pick or create a reviewer. You have two options: \n",
    "    1. Import an existing reviewer (`from JupyterReviewer.Reviewers import PurityReviewer`)\n",
    "    1. Create a reviewer from scratch (see `Developer_Jupyter_Reviewer_Tutorial.ipynb`) and import\n",
    "\n",
    "1. Instantiate the reviewer\n",
    "    1. Set the review object by passing in (1) your dataframe with the data you want to review, (2) a pickle path to save the `ReviewData` object, and (3) any additional parameters required to setup the ReviewData object. You can add or changed annotation columns if you'd like with \n",
    "    1. Set the review app by passing in any of the required parameters\n",
    "1. Run the app\n",
    "\n",
    "Prior to running the app, you can also modify the pre-built reviewer:\n",
    "- `reviewer.review_data.add_annotation({'column name': ReviewDataAnnotation()})`: Add or change an annotation column configuration.\n",
    "- `reviewer.app.add_component(AppComponent(), **kwargs)`: Add a new component\n",
    "- `reviewer.add_autofill()`: if you added another column with `add_annotation()` from above, you can specify how to autofill the annotation panel from an existing component\n",
    "\n",
    "To learn how to add these customizations, see `Developer_Jupyter_Reviewer_Tutorial.ipynb`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b941d6-e24b-44d2-aa8e-1353bcff6b07",
   "metadata": {},
   "source": [
    "Once you have chosen or created your reviewer, you are ready to review data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a693627-edf1-4135-8728-0173dc798085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.) instantiate Your reviewer\n",
    "reviewer = YourReviewer(...)\n",
    "\n",
    "# 2.) set the ReviewData object\n",
    "reviewer.set_review_data(...)\n",
    "\n",
    "# set the review app\n",
    "reviewer.set_review_app(...)\n",
    "\n",
    "# run the app\n",
    "reviewer.run(...)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
